## YOLObile: Real-Time Object Detection on Mobile Devices via Compression-Compilation Co-Design

### 摘要

​		目标检测技术的迅速发展和广泛使用引起了对目标检测器的准确性和速度的关注。但是，当前的最新目标检测工作要么使用大型模型以准确性为导向，但导致高延迟，要么使用轻量级模型以速度为导向，但牺牲准确性。在这项工作中，我们提出YOLObile框架，但是通过压缩编译协同设计（compression-compilation co-design）在移动设备上进行实时目标检测。针对任何核大小，提出了一种新颖的块打孔（block-punched）剪枝方案。为了提高移动设备上的计算效率，采用GPU-CPU协作方案以及高级编译器辅助的优化。实验结果表明，我们的裁剪方案以49.0 mAP将YOLOv4压缩到原始的14分之一。在我们的YOLObile框架之下，使用Samsung Galaxy S20上的GPU获得17FPS的推理速度。纳入我们所提出的GPU-CPU协同方案，推理速度增加到19.1FPS，并且比原始的YOLOv4加速5倍。源代码见https://github.com/nightsnack/YOLObile。

### 1	引言

​		由于深度神经网络（DNN）的爆发，目标检测（计算机视觉领域的主要任务之一）已被广泛研究。目标检测在大量计算机视觉任务中被广泛采用，这些任务包括图像标注、事件检测、目标跟踪、分割和动作识别，并具有广泛应用，例如自动驾驶、UAV避障、机器视觉、人机交互和增强现实。考虑到这些应用场景，当在资源有限的平台上部署如此应用时，同时维持高准确率和低延迟同等重要，尤其是移动和嵌入设备。

​		在过去十年，提出许多有前途的目标检测方法，它们主要被分为两阶段检测器和一阶段检测器。与两阶段检测器相比，一阶段检测器旨在提供准确率和速度之间提供合理的平衡，并将在这项工作中重点讨论。尽管付出了巨大的努力，但有代表性的作品如“You Only Look Once”（YOLO）（Redmon等，2016；Redmon和Farhadi 2017、2018； Bochkovskiy、Wang和Liao 2020）、Single Shot Detector（SSD）（Liu等，2016年），仍然需要大量计算才能实现高平均平均精度（mAP），这导致了在移动设备上实时部署的主要限制。除了上述大尺度方法外，研究了针对移动设备的轻量级目标检测架构（Sandler等人2018a；Huang、Pedoeem和Chen 2018；Li等2018）。 但是，完成的效率会导致精度下降不可忽略。

​		为了在目标检测器中处理这个问题，模型压缩技术已取得关注，尤其是权重裁剪方法，其已被证明是在不牺牲准确性的情况下减少大量计算和内存强度的最有效方法之一（Wen等人2016；Guo、Yao和Chen 2016; Min等人2018；He等2018、2019） 。通过减少权重数量上的大量冗余，具有结构稀疏性的模型可以实现更高的内存和电源效率，并在推理过程中具有低延迟。一般而言，非结构化裁剪和结构化裁剪是权重裁剪的两个主要趋势。非结构化裁剪以非规则方式消除权重，其导致妨碍硬件加速的关键缺点。由于在裁剪整个滤波器/通道中的粗粒度本质，观察到结构化裁剪的精度明显下降。为了克服这些缺点，提出了一种基于模式的裁剪，它以硬件感知的方式结合了细粒度的非结构化裁剪（Ma等2020a； Niu等2020）。但是，它仅适合具有$3 \times 3$核的卷积层（CONV），明显限制它在目标检测任务中的应用。

​		本文的目的是通过利用裁剪在移动平台上进行推理的全部优势来实现实时目标检测。我们提出