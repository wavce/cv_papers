## Twins: Revisiting the Design of Spatial Attention in Vision Transformers

代码见https://git.io/Twins。

### 1. 引言

​		将transformer用于视觉任务的一个主要问题是transformer中空间自注意力的操作引起的繁重计算复杂度，它在输入图像的像素数量上呈二次方增长。一种解决方法是局部分组的自注意力（或在最近的 Swin Transformer [4] 中的非重叠窗口中的自注意力），其中输入在空间上分组为非重叠窗口，并且标准自注意力仅在每个子窗口内计算。尽管它可以明显减小复杂度，但是它缺乏不同窗口之间的连接，并且产生有限的感受野。足够大的感受野是性能的关键，特别是对于诸如图像分割和目标检测的密集预测任务。Swin提出一种平移窗口操作来处理这个问题，其中这些局部窗口的边界随着网络的深入而逐渐移动。尽管有效，但移位的窗口可能具有不均匀的大小。当使用现代深度学习框架（倾向于相等大小的窗口）实现时，不均匀的窗口难以实现。PVT[8]提出另一种解决方案。与标准的自注意力操作（其中每个查询利用所有输入token计算注意力权重）不同，在PVT中，每个查询斤利用输入token的子采样版计算注意力。理论上，它的计算复杂度仍是二次方，但是它在实践中已是可管理的。

​		从一个统一的角度，前面提到的视觉transformer中的核心是如何设计空间注意力。因此，本文中，我们回顾视觉transformer中空间注意力的设计。第一个发现是，PVT中全局子采样注意力高度有效。

